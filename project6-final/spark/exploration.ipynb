{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from etl import (create_spark_session)\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../dwh.cfg\")\n",
    "spark = create_spark_session(config.get(\"AWS\", \"KEY\"), config.get(\"AWS\", \"SECRET\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Crash Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1729860"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accidents = spark.read.option(\"header\",True).csv(config.get(\"S3\", \"CRASH_DATA_LOC\")).cache()\n",
    "df_accidents.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CRASH DATE: string (nullable = true)\n",
      " |-- CRASH TIME: string (nullable = true)\n",
      " |-- BOROUGH: string (nullable = true)\n",
      " |-- ZIP CODE: string (nullable = true)\n",
      " |-- LATITUDE: string (nullable = true)\n",
      " |-- LONGITUDE: string (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      " |-- ON STREET NAME: string (nullable = true)\n",
      " |-- CROSS STREET NAME: string (nullable = true)\n",
      " |-- OFF STREET NAME: string (nullable = true)\n",
      " |-- NUMBER OF PERSONS INJURED: string (nullable = true)\n",
      " |-- NUMBER OF PERSONS KILLED: string (nullable = true)\n",
      " |-- NUMBER OF PEDESTRIANS INJURED: string (nullable = true)\n",
      " |-- NUMBER OF PEDESTRIANS KILLED: string (nullable = true)\n",
      " |-- NUMBER OF CYCLIST INJURED: string (nullable = true)\n",
      " |-- NUMBER OF CYCLIST KILLED: string (nullable = true)\n",
      " |-- NUMBER OF MOTORIST INJURED: string (nullable = true)\n",
      " |-- NUMBER OF MOTORIST KILLED: string (nullable = true)\n",
      " |-- CONTRIBUTING FACTOR VEHICLE 1: string (nullable = true)\n",
      " |-- CONTRIBUTING FACTOR VEHICLE 2: string (nullable = true)\n",
      " |-- CONTRIBUTING FACTOR VEHICLE 3: string (nullable = true)\n",
      " |-- CONTRIBUTING FACTOR VEHICLE 4: string (nullable = true)\n",
      " |-- CONTRIBUTING FACTOR VEHICLE 5: string (nullable = true)\n",
      " |-- COLLISION_ID: string (nullable = true)\n",
      " |-- VEHICLE TYPE CODE 1: string (nullable = true)\n",
      " |-- VEHICLE TYPE CODE 2: string (nullable = true)\n",
      " |-- VEHICLE TYPE CODE 3: string (nullable = true)\n",
      " |-- VEHICLE TYPE CODE 4: string (nullable = true)\n",
      " |-- VEHICLE TYPE CODE 5: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_accidents.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Data Quality Issues:\n",
    "\n",
    "1)`CRASH DATE` column is inferred as string type\n",
    "\n",
    "2)`NUMBER OF ...` column types are inferred as string types\n",
    "\n",
    "3) 2 records with COLLISION_ID = NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|COLLISION_ID|count|\n",
      "+------------+-----+\n",
      "|        null|    2|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import * \n",
    "df_accidents.select(\"COLLISION_ID\").groupBy(\"COLLISION_ID\").count().where(col(\"count\") > 1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "4) Required columns: `CRASH_DATE`, `LATITUDE` and `LONGITUDE` contains null values\n",
    "\n",
    "Total Count: 1,729,860, Corrupt rows: 206,273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206273"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accidents.filter(col(\"CRASH DATE\").isNull() | col(\"LATITUDE\").isNull() | col(\"LONGITUDE\").isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "5) some vechicle_type_list letter casing impacts factors.\n",
    "\n",
    "Example: Taxi, TAXI, or taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|factor|\n",
      "+------+\n",
      "|TAXI  |\n",
      "|Taxi  |\n",
      "|taxi  |\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_accidents.select(\n",
    "     array_distinct(array(\n",
    "          col(\"VEHICLE TYPE CODE 1\"),\n",
    "          col(\"VEHICLE TYPE CODE 2\"),\n",
    "          col(\"VEHICLE TYPE CODE 3\"),\n",
    "          col(\"VEHICLE TYPE CODE 4\"),\n",
    "          col(\"VEHICLE TYPE CODE 5\")\n",
    "         )).alias(\"vechicle_type_list\"))\\\n",
    "    .select(\n",
    "        explode(\"vechicle_type_list\").alias(\"factor\")\n",
    "    ).filter(col(\"factor\").rlike(\"(?i)^taxi$\")).distinct().show(20, False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "6) contributing_factor_list contains 2 unexpected numerical values: 1 and 80. Needs to be fixed in the source system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|factor|is_numerical|\n",
      "+------+------------+\n",
      "|     1|           1|\n",
      "|    80|          80|\n",
      "+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_accidents.select(\n",
    "    array_distinct(array(col(\"CONTRIBUTING FACTOR VEHICLE 1\"),\n",
    "            col(\"CONTRIBUTING FACTOR VEHICLE 2\"),\n",
    "            col(\"CONTRIBUTING FACTOR VEHICLE 3\"),\n",
    "           col(\"CONTRIBUTING FACTOR VEHICLE 4\"),\n",
    "           col(\"CONTRIBUTING FACTOR VEHICLE 5\"),\n",
    "    )).alias(\"contributing_factor_list\")).select(\n",
    "        explode(\"contributing_factor_list\").alias(\"factor\"))\\\n",
    "        .withColumn(\"is_numerical\", expr(\"cast(factor as int)\") ).filter(col(\"is_numerical\") > 0).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Data Quality fixing strategy in ETL\n",
    "\n",
    "1)`CRASH DATE` -  cast to `DateType()`\n",
    "\n",
    "2) All `NUMBER OF ...` - cast to `IntegerType()`\n",
    "\n",
    "3) Required columns: `CRASH_DATE`, `LATITUDE` and `LONGITUDE` contains null values - DROP Rows where required column missing\n",
    "\n",
    "4) 2 records with COLLISION_ID = NULL - drop rows where COLLISION_ID = NULL\n",
    "\n",
    "5) some vechicle_type_list letter casing impacts factors - convert all factors to uppercase()\n",
    "\n",
    "6) contributing_factor_list contains 2 unexpected numerical values - N/A Should be fixed at the source level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Accident Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: string (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- extra: string (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- improvement_surcharge: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- congestion_surcharge: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_taxi = spark.read.option(\"header\",True).csv(config.get(\"S3\", \"NYC_TAXI_DATA_LOC\"))\n",
    "df_taxi.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16847778"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_taxi.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Data Quality Issues:\n",
    "\n",
    "1) `VendorId`, inferred incorrect data type\n",
    "\n",
    "2) 280,883 NULL Values in `VendorID`\n",
    "\n",
    "3) `tpep_pickup_datetime` and `tpep_dropoff_datetime` data type inferred incorrectly\n",
    "\n",
    "4) `total_amount` data type inferred incorrectly\n",
    "\n",
    "5) `PULocationID` and `DOLocationID`. data type inferred incorrectly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280883"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_taxi.filter(col(\"VendorID\").isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Data Quality fixing strategy in ETL\n",
    "\n",
    "- Correct type casting \n",
    "- Replace missing VendorID's with -1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
