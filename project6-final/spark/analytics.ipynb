{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from etl import (create_spark_session, transform_load_location_dim)\n",
    "from model import (create_model)\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../dwh.cfg\")\n",
    "spark = create_spark_session(config.get(\"AWS\", \"KEY\"), config.get(\"AWS\", \"SECRET\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Create analytics model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully created analytics model. Please configure and run etl.py\n"
     ]
    }
   ],
   "source": [
    "create_model(spark)\n",
    "print(\"Succesfully created analytics model. Please configure and run etl.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------+\n",
      "|col_name|data_type|comment|\n",
      "+--------+---------+-------+\n",
      "|date_key|      int|   null|\n",
      "|     day|  tinyint|   null|\n",
      "|    week|  tinyint|   null|\n",
      "|   month|  tinyint|   null|\n",
      "| quarter|  tinyint|   null|\n",
      "|    year|      int|   null|\n",
      "+--------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"describe date_dim \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------+-------+\n",
      "|col_name             |data_type    |comment|\n",
      "+---------------------+-------------+-------+\n",
      "|vendor_key           |int          |null   |\n",
      "|pickup_location_key  |int          |null   |\n",
      "|drop_off_location_key|int          |null   |\n",
      "|date_key             |int          |null   |\n",
      "|passenger_count      |int          |null   |\n",
      "|total_payment_amount |decimal(18,2)|null   |\n",
      "|trip_count           |int          |null   |\n",
      "+---------------------+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"describe trip_fact\"\"\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------+-------+\n",
      "|col_name                 |data_type    |comment|\n",
      "+-------------------------+-------------+-------+\n",
      "|date_key                 |int          |null   |\n",
      "|location_key             |int          |null   |\n",
      "|crash_count              |bigint       |null   |\n",
      "|person_injury_count      |bigint       |null   |\n",
      "|person_kill_count        |bigint       |null   |\n",
      "|contributing_factor_list |array<string>|null   |\n",
      "|impacted_participant_list|array<string>|null   |\n",
      "|vehicle_type_list        |array<string>|null   |\n",
      "+-------------------------+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"describe crash_dim\"\"\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------+\n",
      "|col_name    |data_type|comment|\n",
      "+------------+---------+-------+\n",
      "|location_key|int      |null   |\n",
      "|zone        |string   |null   |\n",
      "|borough     |string   |null   |\n",
      "+------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"describe location_dim\"\"\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|col_name  |data_type|comment|\n",
      "+----------+---------+-------+\n",
      "|vendor_key|tinyint  |null   |\n",
      "|name      |string   |null   |\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"describe vendor_dim\"\"\").show(100, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Quality Checks\n",
    "\n",
    "All target tables should have records > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "    # Location dim ETL\n",
    "df_taxi_zone_df = spark.read.option(\"header\",True).csv(config.get(\"S3\", \"ZONE_LOOKUP_DATA_LOC\"))\n",
    "transform_load_location_dim(spark, df_taxi_zone_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.table(\"vendor_dim\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1243097"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.table(\"trip_fact\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.table(\"location_dim\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225996"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.table(\"crash_dim\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.table(\"date_dim\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Count all accidents involving taxi's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   36041|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT Count(*) \n",
    "FROM   crash_dim \n",
    "WHERE  Array_contains(vehicle_type_list, \"TAXI\") \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Identify vendors and crash_count, who's vechicle vechicle have likely been involved in the crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+----------------+\n",
      "|name                        |sum(crash_count)|\n",
      "+----------------------------+----------------+\n",
      "|Creative Mobile Technologies|116061          |\n",
      "|VeriFone Inc.               |143804          |\n",
      "|Not Available               |52886           |\n",
      "+----------------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"   \n",
    "SELECT v.name, \n",
    "       Sum(c.crash_count) \n",
    "FROM   trip_fact t \n",
    "       JOIN vendor_dim v \n",
    "         ON t.vendor_key = v.vendor_key \n",
    "       JOIN date_dim d \n",
    "         ON d.date_key = t.date_key \n",
    "       JOIN location_dim l \n",
    "         ON t.pickup_location_key = l.location_key \n",
    "             OR t.drop_off_location_key = l.location_key \n",
    "       JOIN crash_dim c \n",
    "         ON c.date_key = d.date_key \n",
    "            AND c.location_key = l.location_key \n",
    "WHERE  Array_contains(c.vehicle_type_list, \"TAXI\") \n",
    "GROUP  BY v.name \n",
    "\"\"\").show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Find TOP 10 accident contributing factors involving taxis for each taxi vendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+------------------------------+------------+----+\n",
      "|vendor                      |factor                        |factor_count|rank|\n",
      "+----------------------------+------------------------------+------------+----+\n",
      "|Creative Mobile Technologies|UNSPECIFIED                   |40790       |1   |\n",
      "|Creative Mobile Technologies|DRIVER INATTENTION/DISTRACTION|25828       |2   |\n",
      "|Creative Mobile Technologies|FOLLOWING TOO CLOSELY         |8727        |3   |\n",
      "|Creative Mobile Technologies|PASSING OR LANE USAGE IMPROPER|7900        |4   |\n",
      "|Creative Mobile Technologies|FAILURE TO YIELD RIGHT-OF-WAY |7044        |5   |\n",
      "|Creative Mobile Technologies|OTHER VEHICULAR               |5026        |6   |\n",
      "|Creative Mobile Technologies|PASSING TOO CLOSELY           |4956        |7   |\n",
      "|Creative Mobile Technologies|UNSAFE LANE CHANGING          |4030        |8   |\n",
      "|Creative Mobile Technologies|BACKING UNSAFELY              |3081        |9   |\n",
      "|Creative Mobile Technologies|TURNING IMPROPERLY            |2710        |10  |\n",
      "|Not Available               |UNSPECIFIED                   |14341       |1   |\n",
      "|Not Available               |DRIVER INATTENTION/DISTRACTION|9665        |2   |\n",
      "|Not Available               |FOLLOWING TOO CLOSELY         |2988        |3   |\n",
      "|Not Available               |FAILURE TO YIELD RIGHT-OF-WAY |2844        |4   |\n",
      "|Not Available               |OTHER VEHICULAR               |2778        |5   |\n",
      "|Not Available               |PASSING OR LANE USAGE IMPROPER|2479        |6   |\n",
      "|Not Available               |PASSING TOO CLOSELY           |1899        |7   |\n",
      "|Not Available               |UNSAFE LANE CHANGING          |1600        |8   |\n",
      "|Not Available               |BACKING UNSAFELY              |1416        |9   |\n",
      "|Not Available               |UNSAFE SPEED                  |1267        |10  |\n",
      "|VeriFone Inc.               |UNSPECIFIED                   |50005       |1   |\n",
      "|VeriFone Inc.               |DRIVER INATTENTION/DISTRACTION|31693       |2   |\n",
      "|VeriFone Inc.               |FOLLOWING TOO CLOSELY         |10834       |3   |\n",
      "|VeriFone Inc.               |PASSING OR LANE USAGE IMPROPER|9584        |4   |\n",
      "|VeriFone Inc.               |FAILURE TO YIELD RIGHT-OF-WAY |8433        |5   |\n",
      "|VeriFone Inc.               |OTHER VEHICULAR               |6285        |6   |\n",
      "|VeriFone Inc.               |PASSING TOO CLOSELY           |6005        |7   |\n",
      "|VeriFone Inc.               |UNSAFE LANE CHANGING          |4990        |8   |\n",
      "|VeriFone Inc.               |BACKING UNSAFELY              |3911        |9   |\n",
      "|VeriFone Inc.               |TURNING IMPROPERLY            |3385        |10  |\n",
      "+----------------------------+------------------------------+------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT   * \n",
    "FROM     ( \n",
    "                  SELECT   *, \n",
    "                           Rank() OVER (partition BY vendor ORDER BY factor_count DESC) AS rank \n",
    "                  FROM     ( \n",
    "                                    SELECT   vendor, \n",
    "                                             factor, \n",
    "                                             Count(*) AS factor_count \n",
    "                                    FROM     ( \n",
    "                                                    SELECT v.NAME                              AS vendor,\n",
    "                                                           Explode(c.contributing_factor_list) AS factor\n",
    "                                                    FROM   trip_fact t \n",
    "                                                    JOIN   vendor_dim v \n",
    "                                                    ON     t.vendor_key = v.vendor_key \n",
    "                                                    JOIN   date_dim d \n",
    "                                                    ON     d.date_key = t.date_key \n",
    "                                                    JOIN   location_dim l \n",
    "                                                    ON     t.pickup_location_key = l.location_key \n",
    "                                                    OR     t.drop_off_location_key = l.location_key\n",
    "                                                    JOIN   crash_dim c \n",
    "                                                    ON     c.date_key = d.date_key \n",
    "                                                    AND    c.location_key = l.location_key \n",
    "                                                    WHERE  Array_contains(c.vehicle_type_list, \"TAXI\"))\n",
    "                                    GROUP BY vendor, \n",
    "                                             factor)) \n",
    "WHERE    rank <= 10 \n",
    "ORDER BY vendor, rank\n",
    "\n",
    "\"\"\").show(100, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
